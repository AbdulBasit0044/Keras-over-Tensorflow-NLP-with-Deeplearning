{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data, test_data = imdb['train'], imdb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "\n",
    "for s,l in train_data:\n",
    "    training_sentences.append(str(s.numpy()))\n",
    "    training_labels.append(l.numpy())\n",
    "    \n",
    "for s,l in test_data:\n",
    "    testing_sentences.append(str(s.numpy()))\n",
    "    testing_labels.append(l.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'this was a wonderfully clever and entertaining movie that i shall never tire of watching many many times the casting was magnificent in matching up the young with the older characters there are those of us out here who really do appreciate good actors and an intelligent story format as for <OOV> <OOV> she is beautiful and a gift to any kind of production in which she stars i always make a point to see <OOV> <OOV> in all her performances she is a superb actress and a pleasure to watch as each transformation of her character comes to life i can only be grateful when i see such an outstanding picture for most of the motion pictures made more\n",
      "b'This was a wonderfully clever and entertaining movie that I shall never tire of watching many, many times. The casting was magnificent in matching up the young with the older characters. There are those of us out here who really do appreciate good actors and an intelligent story format. As for Judi Dench, she is beautiful and a gift to any kind of production in which she stars. I always make a point to see Judi Dench in all her performances. She is a superb actress and a pleasure to watch as each transformation of her character comes to life. I can only be grateful when I see such an outstanding picture for most of the motion pictures made more recently lack good characters, good scripts and good acting. The movie public needs heroes, not deviant manikins, who lack ingenuity and talent. How wonderful to see old favorites like Leslie Caron, Olympia Dukakis and Cleo Laine. I would like to see this movie win the awards it deserves. Thank you again for a tremendous night of entertainment. I congratulate the writer, director, producer, and all those who did such a fine job.'\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[1]))\n",
    "print(training_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - ETA: 1:38 - loss: 1.1418e-06 - acc: 1.000 - ETA: 15s - loss: 2.6357e-06 - acc: 1.000 - ETA: 10s - loss: 2.2848e-06 - acc: 1.00 - ETA: 8s - loss: 2.1824e-06 - acc: 1.0000 - ETA: 7s - loss: 2.2002e-06 - acc: 1.000 - ETA: 7s - loss: 2.1537e-06 - acc: 1.000 - ETA: 6s - loss: 2.1675e-06 - acc: 1.000 - ETA: 6s - loss: 2.1250e-06 - acc: 1.000 - ETA: 6s - loss: 2.0971e-06 - acc: 1.000 - ETA: 6s - loss: 2.0333e-06 - acc: 1.000 - ETA: 5s - loss: 1.9630e-06 - acc: 1.000 - ETA: 5s - loss: 1.9454e-06 - acc: 1.000 - ETA: 5s - loss: 1.9067e-06 - acc: 1.000 - ETA: 5s - loss: 1.9159e-06 - acc: 1.000 - ETA: 5s - loss: 1.8994e-06 - acc: 1.000 - ETA: 5s - loss: 1.8875e-06 - acc: 1.000 - ETA: 5s - loss: 1.8433e-06 - acc: 1.000 - ETA: 5s - loss: 1.8374e-06 - acc: 1.000 - ETA: 4s - loss: 1.8095e-06 - acc: 1.000 - ETA: 4s - loss: 1.7882e-06 - acc: 1.000 - ETA: 4s - loss: 1.7619e-06 - acc: 1.000 - ETA: 4s - loss: 1.7586e-06 - acc: 1.000 - ETA: 4s - loss: 1.7190e-06 - acc: 1.000 - ETA: 4s - loss: 1.6801e-06 - acc: 1.000 - ETA: 3s - loss: 1.6462e-06 - acc: 1.000 - ETA: 3s - loss: 1.6052e-06 - acc: 1.000 - ETA: 3s - loss: 1.5815e-06 - acc: 1.000 - ETA: 3s - loss: 1.5485e-06 - acc: 1.000 - ETA: 3s - loss: 1.5345e-06 - acc: 1.000 - ETA: 3s - loss: 1.9644e-06 - acc: 1.000 - ETA: 3s - loss: 2.1552e-06 - acc: 1.000 - ETA: 3s - loss: 2.3566e-06 - acc: 1.000 - ETA: 2s - loss: 2.4216e-06 - acc: 1.000 - ETA: 2s - loss: 2.4385e-06 - acc: 1.000 - ETA: 2s - loss: 2.4035e-06 - acc: 1.000 - ETA: 2s - loss: 2.4090e-06 - acc: 1.000 - ETA: 2s - loss: 2.4345e-06 - acc: 1.000 - ETA: 2s - loss: 2.4340e-06 - acc: 1.000 - ETA: 2s - loss: 2.4189e-06 - acc: 1.000 - ETA: 2s - loss: 2.3906e-06 - acc: 1.000 - ETA: 2s - loss: 2.3603e-06 - acc: 1.000 - ETA: 2s - loss: 2.3583e-06 - acc: 1.000 - ETA: 2s - loss: 2.3527e-06 - acc: 1.000 - ETA: 2s - loss: 2.3845e-06 - acc: 1.000 - ETA: 1s - loss: 2.3649e-06 - acc: 1.000 - ETA: 1s - loss: 2.4003e-06 - acc: 1.000 - ETA: 1s - loss: 2.4065e-06 - acc: 1.000 - ETA: 1s - loss: 2.4220e-06 - acc: 1.000 - ETA: 1s - loss: 2.4102e-06 - acc: 1.000 - ETA: 1s - loss: 2.4013e-06 - acc: 1.000 - ETA: 1s - loss: 2.3762e-06 - acc: 1.000 - ETA: 1s - loss: 2.3789e-06 - acc: 1.000 - ETA: 1s - loss: 2.3625e-06 - acc: 1.000 - ETA: 1s - loss: 2.3530e-06 - acc: 1.000 - ETA: 1s - loss: 2.3341e-06 - acc: 1.000 - ETA: 1s - loss: 2.3294e-06 - acc: 1.000 - ETA: 1s - loss: 2.3088e-06 - acc: 1.000 - ETA: 0s - loss: 2.2880e-06 - acc: 1.000 - ETA: 0s - loss: 2.2645e-06 - acc: 1.000 - ETA: 0s - loss: 2.2543e-06 - acc: 1.000 - ETA: 0s - loss: 2.2380e-06 - acc: 1.000 - ETA: 0s - loss: 2.2187e-06 - acc: 1.000 - ETA: 0s - loss: 2.2116e-06 - acc: 1.000 - ETA: 0s - loss: 2.2075e-06 - acc: 1.000 - ETA: 0s - loss: 2.2254e-06 - acc: 1.000 - ETA: 0s - loss: 2.2090e-06 - acc: 1.000 - ETA: 0s - loss: 2.2033e-06 - acc: 1.000 - ETA: 0s - loss: 2.1819e-06 - acc: 1.000 - ETA: 0s - loss: 2.1599e-06 - acc: 1.000 - ETA: 0s - loss: 2.1473e-06 - acc: 1.000 - ETA: 0s - loss: 2.1372e-06 - acc: 1.000 - ETA: 0s - loss: 2.1412e-06 - acc: 1.000 - ETA: 0s - loss: 2.1587e-06 - acc: 1.000 - ETA: 0s - loss: 2.1553e-06 - acc: 1.000 - 5s 211us/sample - loss: 2.1535e-06 - acc: 1.0000 - val_loss: 1.2876 - val_acc: 0.8211\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - ETA: 5s - loss: 1.4529e-07 - acc: 1.000 - ETA: 3s - loss: 4.5267e-04 - acc: 1.000 - ETA: 3s - loss: 3.1374e-04 - acc: 1.000 - ETA: 3s - loss: 2.2338e-04 - acc: 1.000 - ETA: 3s - loss: 5.6403e-04 - acc: 1.000 - ETA: 3s - loss: 5.2482e-04 - acc: 1.000 - ETA: 3s - loss: 4.4673e-04 - acc: 1.000 - ETA: 3s - loss: 0.0011 - acc: 0.9996    - ETA: 3s - loss: 0.0020 - acc: 0.999 - ETA: 3s - loss: 0.0019 - acc: 0.999 - ETA: 2s - loss: 0.0018 - acc: 0.999 - ETA: 2s - loss: 0.0017 - acc: 0.999 - ETA: 2s - loss: 0.0018 - acc: 0.999 - ETA: 2s - loss: 0.0017 - acc: 0.999 - ETA: 2s - loss: 0.0018 - acc: 0.999 - ETA: 2s - loss: 0.0017 - acc: 0.999 - ETA: 2s - loss: 0.0017 - acc: 0.999 - ETA: 2s - loss: 0.0018 - acc: 0.999 - ETA: 2s - loss: 0.0017 - acc: 0.999 - ETA: 2s - loss: 0.0018 - acc: 0.999 - ETA: 2s - loss: 0.0028 - acc: 0.998 - ETA: 2s - loss: 0.0028 - acc: 0.999 - ETA: 2s - loss: 0.0027 - acc: 0.999 - ETA: 2s - loss: 0.0026 - acc: 0.999 - ETA: 2s - loss: 0.0025 - acc: 0.999 - ETA: 2s - loss: 0.0024 - acc: 0.999 - ETA: 2s - loss: 0.0024 - acc: 0.999 - ETA: 2s - loss: 0.0023 - acc: 0.999 - ETA: 1s - loss: 0.0023 - acc: 0.999 - ETA: 1s - loss: 0.0022 - acc: 0.999 - ETA: 1s - loss: 0.0021 - acc: 0.999 - ETA: 1s - loss: 0.0021 - acc: 0.999 - ETA: 1s - loss: 0.0020 - acc: 0.999 - ETA: 1s - loss: 0.0020 - acc: 0.999 - ETA: 1s - loss: 0.0022 - acc: 0.999 - ETA: 1s - loss: 0.0022 - acc: 0.999 - ETA: 1s - loss: 0.0021 - acc: 0.999 - ETA: 1s - loss: 0.0021 - acc: 0.999 - ETA: 1s - loss: 0.0021 - acc: 0.999 - ETA: 1s - loss: 0.0021 - acc: 0.999 - ETA: 1s - loss: 0.0022 - acc: 0.999 - ETA: 1s - loss: 0.0022 - acc: 0.999 - ETA: 1s - loss: 0.0023 - acc: 0.999 - ETA: 1s - loss: 0.0023 - acc: 0.999 - ETA: 1s - loss: 0.0022 - acc: 0.999 - ETA: 1s - loss: 0.0022 - acc: 0.999 - ETA: 1s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0023 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0026 - acc: 0.999 - ETA: 0s - loss: 0.0026 - acc: 0.999 - ETA: 0s - loss: 0.0026 - acc: 0.999 - 5s 181us/sample - loss: 0.0026 - acc: 0.9990 - val_loss: 1.4829 - val_acc: 0.8104\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 6s - loss: 2.9087e-05 - acc: 1.000 - ETA: 3s - loss: 3.9564e-05 - acc: 1.000 - ETA: 3s - loss: 5.1998e-05 - acc: 1.000 - ETA: 3s - loss: 9.1947e-05 - acc: 1.000 - ETA: 3s - loss: 1.8278e-04 - acc: 1.000 - ETA: 3s - loss: 1.5744e-04 - acc: 1.000 - ETA: 3s - loss: 2.0180e-04 - acc: 1.000 - ETA: 3s - loss: 1.8498e-04 - acc: 1.000 - ETA: 3s - loss: 1.8378e-04 - acc: 1.000 - ETA: 3s - loss: 1.7846e-04 - acc: 1.000 - ETA: 3s - loss: 1.6667e-04 - acc: 1.000 - ETA: 3s - loss: 1.9059e-04 - acc: 1.000 - ETA: 3s - loss: 1.8259e-04 - acc: 1.000 - ETA: 3s - loss: 1.6853e-04 - acc: 1.000 - ETA: 3s - loss: 1.5733e-04 - acc: 1.000 - ETA: 3s - loss: 1.7003e-04 - acc: 1.000 - ETA: 2s - loss: 1.8679e-04 - acc: 1.000 - ETA: 2s - loss: 1.7441e-04 - acc: 1.000 - ETA: 2s - loss: 1.8076e-04 - acc: 1.000 - ETA: 2s - loss: 1.6999e-04 - acc: 1.000 - ETA: 2s - loss: 1.8666e-04 - acc: 1.000 - ETA: 2s - loss: 1.8006e-04 - acc: 1.000 - ETA: 2s - loss: 1.7228e-04 - acc: 1.000 - ETA: 2s - loss: 1.7175e-04 - acc: 1.000 - ETA: 2s - loss: 1.6594e-04 - acc: 1.000 - ETA: 2s - loss: 1.6051e-04 - acc: 1.000 - ETA: 2s - loss: 1.5509e-04 - acc: 1.000 - ETA: 2s - loss: 1.5388e-04 - acc: 1.000 - ETA: 2s - loss: 1.5794e-04 - acc: 1.000 - ETA: 2s - loss: 1.5710e-04 - acc: 1.000 - ETA: 2s - loss: 1.5614e-04 - acc: 1.000 - ETA: 1s - loss: 1.5429e-04 - acc: 1.000 - ETA: 1s - loss: 1.5032e-04 - acc: 1.000 - ETA: 1s - loss: 1.7195e-04 - acc: 1.000 - ETA: 1s - loss: 1.7821e-04 - acc: 1.000 - ETA: 1s - loss: 1.7325e-04 - acc: 1.000 - ETA: 1s - loss: 1.7103e-04 - acc: 1.000 - ETA: 1s - loss: 1.6974e-04 - acc: 1.000 - ETA: 1s - loss: 1.6875e-04 - acc: 1.000 - ETA: 1s - loss: 1.6497e-04 - acc: 1.000 - ETA: 1s - loss: 1.6199e-04 - acc: 1.000 - ETA: 1s - loss: 2.1458e-04 - acc: 0.999 - ETA: 1s - loss: 2.1785e-04 - acc: 0.999 - ETA: 1s - loss: 2.1443e-04 - acc: 0.999 - ETA: 1s - loss: 2.2099e-04 - acc: 0.999 - ETA: 1s - loss: 2.2013e-04 - acc: 0.999 - ETA: 1s - loss: 2.1543e-04 - acc: 0.999 - ETA: 1s - loss: 2.3782e-04 - acc: 0.999 - ETA: 1s - loss: 2.3610e-04 - acc: 0.999 - ETA: 0s - loss: 2.3149e-04 - acc: 0.999 - ETA: 0s - loss: 2.2687e-04 - acc: 0.999 - ETA: 0s - loss: 2.2365e-04 - acc: 0.999 - ETA: 0s - loss: 2.1940e-04 - acc: 0.999 - ETA: 0s - loss: 2.1573e-04 - acc: 0.999 - ETA: 0s - loss: 2.1299e-04 - acc: 0.999 - ETA: 0s - loss: 2.1518e-04 - acc: 1.000 - ETA: 0s - loss: 2.1191e-04 - acc: 1.000 - ETA: 0s - loss: 2.0943e-04 - acc: 1.000 - ETA: 0s - loss: 2.0745e-04 - acc: 1.000 - ETA: 0s - loss: 2.0389e-04 - acc: 1.000 - ETA: 0s - loss: 2.0332e-04 - acc: 1.000 - ETA: 0s - loss: 1.9989e-04 - acc: 1.000 - ETA: 0s - loss: 1.9851e-04 - acc: 1.000 - ETA: 0s - loss: 2.0656e-04 - acc: 1.000 - ETA: 0s - loss: 2.0379e-04 - acc: 1.000 - ETA: 0s - loss: 2.4624e-04 - acc: 0.999 - ETA: 0s - loss: 2.4775e-04 - acc: 0.999 - 5s 186us/sample - loss: 2.4701e-04 - acc: 0.9999 - val_loss: 1.5083 - val_acc: 0.8104\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - ETA: 4s - loss: 8.1025e-07 - acc: 1.000 - ETA: 3s - loss: 2.7551e-06 - acc: 1.000 - ETA: 3s - loss: 3.5590e-06 - acc: 1.000 - ETA: 3s - loss: 2.8019e-06 - acc: 1.000 - ETA: 3s - loss: 3.2383e-06 - acc: 1.000 - ETA: 3s - loss: 4.1927e-06 - acc: 1.000 - ETA: 3s - loss: 4.0362e-06 - acc: 1.000 - ETA: 3s - loss: 3.9497e-06 - acc: 1.000 - ETA: 3s - loss: 4.0552e-06 - acc: 1.000 - ETA: 3s - loss: 8.0664e-06 - acc: 1.000 - ETA: 3s - loss: 8.2404e-06 - acc: 1.000 - ETA: 2s - loss: 8.1514e-06 - acc: 1.000 - ETA: 2s - loss: 9.6995e-06 - acc: 1.000 - ETA: 2s - loss: 9.1359e-06 - acc: 1.000 - ETA: 2s - loss: 9.4025e-06 - acc: 1.000 - ETA: 2s - loss: 9.4592e-06 - acc: 1.000 - ETA: 2s - loss: 9.4086e-06 - acc: 1.000 - ETA: 2s - loss: 9.2107e-06 - acc: 1.000 - ETA: 2s - loss: 9.0036e-06 - acc: 1.000 - ETA: 2s - loss: 8.7586e-06 - acc: 1.000 - ETA: 2s - loss: 8.5340e-06 - acc: 1.000 - ETA: 2s - loss: 8.3173e-06 - acc: 1.000 - ETA: 2s - loss: 8.1434e-06 - acc: 1.000 - ETA: 2s - loss: 8.0348e-06 - acc: 1.000 - ETA: 2s - loss: 7.7808e-06 - acc: 1.000 - ETA: 2s - loss: 8.3401e-06 - acc: 1.000 - ETA: 2s - loss: 8.4475e-06 - acc: 1.000 - ETA: 2s - loss: 8.7875e-06 - acc: 1.000 - ETA: 2s - loss: 8.5617e-06 - acc: 1.000 - ETA: 2s - loss: 8.7140e-06 - acc: 1.000 - ETA: 2s - loss: 8.7352e-06 - acc: 1.000 - ETA: 2s - loss: 8.6595e-06 - acc: 1.000 - ETA: 1s - loss: 8.4433e-06 - acc: 1.000 - ETA: 1s - loss: 8.2392e-06 - acc: 1.000 - ETA: 1s - loss: 8.8761e-06 - acc: 1.000 - ETA: 1s - loss: 8.9451e-06 - acc: 1.000 - ETA: 1s - loss: 8.7465e-06 - acc: 1.000 - ETA: 1s - loss: 8.5553e-06 - acc: 1.000 - ETA: 1s - loss: 8.6087e-06 - acc: 1.000 - ETA: 1s - loss: 8.4269e-06 - acc: 1.000 - ETA: 1s - loss: 8.2512e-06 - acc: 1.000 - ETA: 1s - loss: 8.1157e-06 - acc: 1.000 - ETA: 1s - loss: 8.0157e-06 - acc: 1.000 - ETA: 1s - loss: 7.8524e-06 - acc: 1.000 - ETA: 1s - loss: 7.6928e-06 - acc: 1.000 - ETA: 1s - loss: 7.8061e-06 - acc: 1.000 - ETA: 1s - loss: 7.6997e-06 - acc: 1.000 - ETA: 1s - loss: 7.7092e-06 - acc: 1.000 - ETA: 1s - loss: 7.5720e-06 - acc: 1.000 - ETA: 0s - loss: 7.4848e-06 - acc: 1.000 - ETA: 0s - loss: 7.3774e-06 - acc: 1.000 - ETA: 0s - loss: 7.3620e-06 - acc: 1.000 - ETA: 0s - loss: 7.2709e-06 - acc: 1.000 - ETA: 0s - loss: 7.2278e-06 - acc: 1.000 - ETA: 0s - loss: 7.1270e-06 - acc: 1.000 - ETA: 0s - loss: 7.0408e-06 - acc: 1.000 - ETA: 0s - loss: 6.9527e-06 - acc: 1.000 - ETA: 0s - loss: 6.9285e-06 - acc: 1.000 - ETA: 0s - loss: 6.8237e-06 - acc: 1.000 - ETA: 0s - loss: 6.8071e-06 - acc: 1.000 - ETA: 0s - loss: 6.7296e-06 - acc: 1.000 - ETA: 0s - loss: 6.6491e-06 - acc: 1.000 - ETA: 0s - loss: 6.5754e-06 - acc: 1.000 - ETA: 0s - loss: 6.5018e-06 - acc: 1.000 - ETA: 0s - loss: 6.5021e-06 - acc: 1.000 - ETA: 0s - loss: 6.4493e-06 - acc: 1.000 - ETA: 0s - loss: 6.3670e-06 - acc: 1.000 - 5s 183us/sample - loss: 6.3663e-06 - acc: 1.0000 - val_loss: 1.4905 - val_acc: 0.8118\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 5s - loss: 1.9819e-06 - acc: 1.000 - ETA: 3s - loss: 1.0981e-06 - acc: 1.000 - ETA: 3s - loss: 1.1838e-06 - acc: 1.000 - ETA: 3s - loss: 1.3750e-06 - acc: 1.000 - ETA: 3s - loss: 1.3030e-06 - acc: 1.000 - ETA: 3s - loss: 1.2671e-06 - acc: 1.000 - ETA: 3s - loss: 1.2894e-06 - acc: 1.000 - ETA: 3s - loss: 1.2488e-06 - acc: 1.000 - ETA: 3s - loss: 1.2338e-06 - acc: 1.000 - ETA: 3s - loss: 1.2053e-06 - acc: 1.000 - ETA: 3s - loss: 1.1764e-06 - acc: 1.000 - ETA: 2s - loss: 1.1315e-06 - acc: 1.000 - ETA: 2s - loss: 1.0880e-06 - acc: 1.000 - ETA: 2s - loss: 1.1272e-06 - acc: 1.000 - ETA: 2s - loss: 1.1247e-06 - acc: 1.000 - ETA: 2s - loss: 1.1406e-06 - acc: 1.000 - ETA: 2s - loss: 1.1147e-06 - acc: 1.000 - ETA: 2s - loss: 1.1339e-06 - acc: 1.000 - ETA: 2s - loss: 1.1159e-06 - acc: 1.000 - ETA: 2s - loss: 1.1038e-06 - acc: 1.000 - ETA: 2s - loss: 1.1127e-06 - acc: 1.000 - ETA: 2s - loss: 1.1204e-06 - acc: 1.000 - ETA: 2s - loss: 1.1348e-06 - acc: 1.000 - ETA: 2s - loss: 1.1687e-06 - acc: 1.000 - ETA: 2s - loss: 1.1626e-06 - acc: 1.000 - ETA: 2s - loss: 1.1629e-06 - acc: 1.000 - ETA: 2s - loss: 1.1509e-06 - acc: 1.000 - ETA: 2s - loss: 1.1435e-06 - acc: 1.000 - ETA: 2s - loss: 1.1283e-06 - acc: 1.000 - ETA: 2s - loss: 1.1151e-06 - acc: 1.000 - ETA: 2s - loss: 1.1161e-06 - acc: 1.000 - ETA: 1s - loss: 1.0997e-06 - acc: 1.000 - ETA: 1s - loss: 1.2660e-06 - acc: 1.000 - ETA: 1s - loss: 1.2528e-06 - acc: 1.000 - ETA: 1s - loss: 1.2400e-06 - acc: 1.000 - ETA: 1s - loss: 1.2386e-06 - acc: 1.000 - ETA: 1s - loss: 1.2227e-06 - acc: 1.000 - ETA: 1s - loss: 1.2148e-06 - acc: 1.000 - ETA: 1s - loss: 1.2105e-06 - acc: 1.000 - ETA: 1s - loss: 1.2163e-06 - acc: 1.000 - ETA: 1s - loss: 1.2155e-06 - acc: 1.000 - ETA: 1s - loss: 1.2229e-06 - acc: 1.000 - ETA: 1s - loss: 1.2175e-06 - acc: 1.000 - ETA: 1s - loss: 1.2097e-06 - acc: 1.000 - ETA: 1s - loss: 1.2017e-06 - acc: 1.000 - ETA: 1s - loss: 1.2084e-06 - acc: 1.000 - ETA: 1s - loss: 1.2037e-06 - acc: 1.000 - ETA: 1s - loss: 1.2078e-06 - acc: 1.000 - ETA: 1s - loss: 1.2069e-06 - acc: 1.000 - ETA: 1s - loss: 1.1986e-06 - acc: 1.000 - ETA: 1s - loss: 1.1999e-06 - acc: 1.000 - ETA: 0s - loss: 1.2006e-06 - acc: 1.000 - ETA: 0s - loss: 1.1945e-06 - acc: 1.000 - ETA: 0s - loss: 1.1980e-06 - acc: 1.000 - ETA: 0s - loss: 1.3026e-06 - acc: 1.000 - ETA: 0s - loss: 1.3414e-06 - acc: 1.000 - ETA: 0s - loss: 1.3344e-06 - acc: 1.000 - ETA: 0s - loss: 1.3325e-06 - acc: 1.000 - ETA: 0s - loss: 1.3289e-06 - acc: 1.000 - ETA: 0s - loss: 1.3223e-06 - acc: 1.000 - ETA: 0s - loss: 1.3198e-06 - acc: 1.000 - ETA: 0s - loss: 1.3093e-06 - acc: 1.000 - ETA: 0s - loss: 1.3558e-06 - acc: 1.000 - ETA: 0s - loss: 1.3609e-06 - acc: 1.000 - ETA: 0s - loss: 1.3504e-06 - acc: 1.000 - ETA: 0s - loss: 1.3444e-06 - acc: 1.000 - ETA: 0s - loss: 1.3330e-06 - acc: 1.000 - ETA: 0s - loss: 1.3252e-06 - acc: 1.000 - ETA: 0s - loss: 1.3353e-06 - acc: 1.000 - ETA: 0s - loss: 1.3309e-06 - acc: 1.000 - 5s 194us/sample - loss: 1.3305e-06 - acc: 1.0000 - val_loss: 1.4930 - val_acc: 0.8111\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - ETA: 4s - loss: 3.5577e-07 - acc: 1.000 - ETA: 3s - loss: 9.0268e-07 - acc: 1.000 - ETA: 3s - loss: 8.3967e-07 - acc: 1.000 - ETA: 3s - loss: 7.5361e-07 - acc: 1.000 - ETA: 3s - loss: 8.4243e-07 - acc: 1.000 - ETA: 3s - loss: 8.9811e-07 - acc: 1.000 - ETA: 3s - loss: 8.6339e-07 - acc: 1.000 - ETA: 3s - loss: 8.2507e-07 - acc: 1.000 - ETA: 3s - loss: 8.1737e-07 - acc: 1.000 - ETA: 3s - loss: 1.2791e-06 - acc: 1.000 - ETA: 3s - loss: 1.2773e-06 - acc: 1.000 - ETA: 3s - loss: 1.2129e-06 - acc: 1.000 - ETA: 3s - loss: 1.1558e-06 - acc: 1.000 - ETA: 3s - loss: 1.2008e-06 - acc: 1.000 - ETA: 2s - loss: 1.1707e-06 - acc: 1.000 - ETA: 2s - loss: 1.1952e-06 - acc: 1.000 - ETA: 2s - loss: 1.1601e-06 - acc: 1.000 - ETA: 2s - loss: 1.1235e-06 - acc: 1.000 - ETA: 2s - loss: 1.0943e-06 - acc: 1.000 - ETA: 2s - loss: 1.1009e-06 - acc: 1.000 - ETA: 2s - loss: 1.1028e-06 - acc: 1.000 - ETA: 2s - loss: 1.0879e-06 - acc: 1.000 - ETA: 2s - loss: 1.0735e-06 - acc: 1.000 - ETA: 2s - loss: 1.0806e-06 - acc: 1.000 - ETA: 2s - loss: 1.0700e-06 - acc: 1.000 - ETA: 2s - loss: 1.1146e-06 - acc: 1.000 - ETA: 2s - loss: 1.0961e-06 - acc: 1.000 - ETA: 2s - loss: 1.0826e-06 - acc: 1.000 - ETA: 2s - loss: 1.0720e-06 - acc: 1.000 - ETA: 2s - loss: 1.0640e-06 - acc: 1.000 - ETA: 2s - loss: 1.1352e-06 - acc: 1.000 - ETA: 2s - loss: 1.1223e-06 - acc: 1.000 - ETA: 2s - loss: 1.1045e-06 - acc: 1.000 - ETA: 2s - loss: 1.1058e-06 - acc: 1.000 - ETA: 2s - loss: 1.0964e-06 - acc: 1.000 - ETA: 1s - loss: 1.0988e-06 - acc: 1.000 - ETA: 1s - loss: 1.0818e-06 - acc: 1.000 - ETA: 1s - loss: 1.0650e-06 - acc: 1.000 - ETA: 1s - loss: 1.0641e-06 - acc: 1.000 - ETA: 1s - loss: 1.0606e-06 - acc: 1.000 - ETA: 1s - loss: 1.0545e-06 - acc: 1.000 - ETA: 1s - loss: 1.0474e-06 - acc: 1.000 - ETA: 1s - loss: 1.0511e-06 - acc: 1.000 - ETA: 1s - loss: 1.0460e-06 - acc: 1.000 - ETA: 1s - loss: 1.0373e-06 - acc: 1.000 - ETA: 1s - loss: 1.0316e-06 - acc: 1.000 - ETA: 1s - loss: 1.0313e-06 - acc: 1.000 - ETA: 1s - loss: 1.0243e-06 - acc: 1.000 - ETA: 1s - loss: 1.0206e-06 - acc: 1.000 - ETA: 1s - loss: 1.0094e-06 - acc: 1.000 - ETA: 1s - loss: 1.0075e-06 - acc: 1.000 - ETA: 1s - loss: 9.9811e-07 - acc: 1.000 - ETA: 1s - loss: 9.9060e-07 - acc: 1.000 - ETA: 1s - loss: 9.8573e-07 - acc: 1.000 - ETA: 0s - loss: 9.8414e-07 - acc: 1.000 - ETA: 0s - loss: 9.7518e-07 - acc: 1.000 - ETA: 0s - loss: 9.7542e-07 - acc: 1.000 - ETA: 0s - loss: 9.7541e-07 - acc: 1.000 - ETA: 0s - loss: 9.6878e-07 - acc: 1.000 - ETA: 0s - loss: 9.6932e-07 - acc: 1.000 - ETA: 0s - loss: 9.6688e-07 - acc: 1.000 - ETA: 0s - loss: 9.6188e-07 - acc: 1.000 - ETA: 0s - loss: 9.5953e-07 - acc: 1.000 - ETA: 0s - loss: 9.5515e-07 - acc: 1.000 - ETA: 0s - loss: 9.6432e-07 - acc: 1.000 - ETA: 0s - loss: 9.6175e-07 - acc: 1.000 - ETA: 0s - loss: 9.5974e-07 - acc: 1.000 - ETA: 0s - loss: 9.7249e-07 - acc: 1.000 - ETA: 0s - loss: 9.7168e-07 - acc: 1.000 - ETA: 0s - loss: 9.6543e-07 - acc: 1.000 - ETA: 0s - loss: 9.6205e-07 - acc: 1.000 - ETA: 0s - loss: 9.6048e-07 - acc: 1.000 - ETA: 0s - loss: 9.5607e-07 - acc: 1.000 - 5s 202us/sample - loss: 9.5632e-07 - acc: 1.0000 - val_loss: 1.4940 - val_acc: 0.8111\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 5s - loss: 7.1712e-07 - acc: 1.000 - ETA: 3s - loss: 7.6856e-07 - acc: 1.000 - ETA: 3s - loss: 7.0364e-07 - acc: 1.000 - ETA: 3s - loss: 6.4544e-07 - acc: 1.000 - ETA: 3s - loss: 6.2242e-07 - acc: 1.000 - ETA: 3s - loss: 7.2501e-07 - acc: 1.000 - ETA: 3s - loss: 6.7390e-07 - acc: 1.000 - ETA: 3s - loss: 7.1479e-07 - acc: 1.000 - ETA: 3s - loss: 6.8456e-07 - acc: 1.000 - ETA: 3s - loss: 6.7374e-07 - acc: 1.000 - ETA: 3s - loss: 6.9070e-07 - acc: 1.000 - ETA: 3s - loss: 6.8384e-07 - acc: 1.000 - ETA: 3s - loss: 7.0262e-07 - acc: 1.000 - ETA: 3s - loss: 6.8885e-07 - acc: 1.000 - ETA: 3s - loss: 6.7743e-07 - acc: 1.000 - ETA: 3s - loss: 6.6900e-07 - acc: 1.000 - ETA: 2s - loss: 6.5200e-07 - acc: 1.000 - ETA: 2s - loss: 6.5262e-07 - acc: 1.000 - ETA: 2s - loss: 6.9280e-07 - acc: 1.000 - ETA: 2s - loss: 6.8841e-07 - acc: 1.000 - ETA: 2s - loss: 6.7974e-07 - acc: 1.000 - ETA: 2s - loss: 6.6920e-07 - acc: 1.000 - ETA: 2s - loss: 6.5701e-07 - acc: 1.000 - ETA: 2s - loss: 6.5012e-07 - acc: 1.000 - ETA: 2s - loss: 6.6021e-07 - acc: 1.000 - ETA: 2s - loss: 6.5254e-07 - acc: 1.000 - ETA: 2s - loss: 6.5081e-07 - acc: 1.000 - ETA: 2s - loss: 6.5445e-07 - acc: 1.000 - ETA: 2s - loss: 6.6287e-07 - acc: 1.000 - ETA: 2s - loss: 6.7201e-07 - acc: 1.000 - ETA: 2s - loss: 6.7057e-07 - acc: 1.000 - ETA: 2s - loss: 6.6229e-07 - acc: 1.000 - ETA: 2s - loss: 6.6644e-07 - acc: 1.000 - ETA: 1s - loss: 6.6489e-07 - acc: 1.000 - ETA: 1s - loss: 6.6749e-07 - acc: 1.000 - ETA: 1s - loss: 6.6420e-07 - acc: 1.000 - ETA: 1s - loss: 6.6993e-07 - acc: 1.000 - ETA: 1s - loss: 6.6487e-07 - acc: 1.000 - ETA: 1s - loss: 6.7444e-07 - acc: 1.000 - ETA: 1s - loss: 6.7529e-07 - acc: 1.000 - ETA: 1s - loss: 6.6919e-07 - acc: 1.000 - ETA: 1s - loss: 6.6902e-07 - acc: 1.000 - ETA: 1s - loss: 6.7836e-07 - acc: 1.000 - ETA: 1s - loss: 6.7880e-07 - acc: 1.000 - ETA: 1s - loss: 6.7840e-07 - acc: 1.000 - ETA: 1s - loss: 6.9555e-07 - acc: 1.000 - ETA: 1s - loss: 6.9371e-07 - acc: 1.000 - ETA: 1s - loss: 6.8674e-07 - acc: 1.000 - ETA: 1s - loss: 6.8163e-07 - acc: 1.000 - ETA: 1s - loss: 6.7922e-07 - acc: 1.000 - ETA: 1s - loss: 6.8878e-07 - acc: 1.000 - ETA: 0s - loss: 6.8771e-07 - acc: 1.000 - ETA: 0s - loss: 6.9490e-07 - acc: 1.000 - ETA: 0s - loss: 6.9036e-07 - acc: 1.000 - ETA: 0s - loss: 6.9540e-07 - acc: 1.000 - ETA: 0s - loss: 6.9386e-07 - acc: 1.000 - ETA: 0s - loss: 7.0808e-07 - acc: 1.000 - ETA: 0s - loss: 7.0675e-07 - acc: 1.000 - ETA: 0s - loss: 7.9932e-07 - acc: 1.000 - ETA: 0s - loss: 7.9998e-07 - acc: 1.000 - ETA: 0s - loss: 8.0417e-07 - acc: 1.000 - ETA: 0s - loss: 7.9776e-07 - acc: 1.000 - ETA: 0s - loss: 7.9806e-07 - acc: 1.000 - ETA: 0s - loss: 7.9842e-07 - acc: 1.000 - ETA: 0s - loss: 7.9402e-07 - acc: 1.000 - ETA: 0s - loss: 7.9134e-07 - acc: 1.000 - ETA: 0s - loss: 7.9119e-07 - acc: 1.000 - ETA: 0s - loss: 7.9009e-07 - acc: 1.000 - ETA: 0s - loss: 7.8543e-07 - acc: 1.000 - 5s 193us/sample - loss: 7.8443e-07 - acc: 1.0000 - val_loss: 1.4947 - val_acc: 0.8112\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - ETA: 4s - loss: 4.1351e-07 - acc: 1.000 - ETA: 3s - loss: 7.1800e-07 - acc: 1.000 - ETA: 3s - loss: 5.8542e-07 - acc: 1.000 - ETA: 3s - loss: 6.0816e-07 - acc: 1.000 - ETA: 3s - loss: 6.0152e-07 - acc: 1.000 - ETA: 3s - loss: 5.9732e-07 - acc: 1.000 - ETA: 3s - loss: 5.6929e-07 - acc: 1.000 - ETA: 3s - loss: 5.3885e-07 - acc: 1.000 - ETA: 3s - loss: 5.2382e-07 - acc: 1.000 - ETA: 3s - loss: 5.2059e-07 - acc: 1.000 - ETA: 3s - loss: 5.0685e-07 - acc: 1.000 - ETA: 3s - loss: 5.5818e-07 - acc: 1.000 - ETA: 3s - loss: 5.5604e-07 - acc: 1.000 - ETA: 3s - loss: 5.8701e-07 - acc: 1.000 - ETA: 2s - loss: 5.8795e-07 - acc: 1.000 - ETA: 2s - loss: 5.8254e-07 - acc: 1.000 - ETA: 2s - loss: 5.7313e-07 - acc: 1.000 - ETA: 2s - loss: 6.4002e-07 - acc: 1.000 - ETA: 2s - loss: 6.3530e-07 - acc: 1.000 - ETA: 2s - loss: 6.3471e-07 - acc: 1.000 - ETA: 2s - loss: 6.3339e-07 - acc: 1.000 - ETA: 2s - loss: 6.2335e-07 - acc: 1.000 - ETA: 2s - loss: 6.1941e-07 - acc: 1.000 - ETA: 2s - loss: 6.1790e-07 - acc: 1.000 - ETA: 2s - loss: 6.0600e-07 - acc: 1.000 - ETA: 2s - loss: 5.9943e-07 - acc: 1.000 - ETA: 2s - loss: 5.9651e-07 - acc: 1.000 - ETA: 2s - loss: 6.1299e-07 - acc: 1.000 - ETA: 2s - loss: 6.0654e-07 - acc: 1.000 - ETA: 2s - loss: 6.1162e-07 - acc: 1.000 - ETA: 2s - loss: 6.0351e-07 - acc: 1.000 - ETA: 2s - loss: 6.0460e-07 - acc: 1.000 - ETA: 2s - loss: 6.0486e-07 - acc: 1.000 - ETA: 2s - loss: 5.9731e-07 - acc: 1.000 - ETA: 2s - loss: 5.9721e-07 - acc: 1.000 - ETA: 2s - loss: 5.9940e-07 - acc: 1.000 - ETA: 1s - loss: 6.0074e-07 - acc: 1.000 - ETA: 1s - loss: 6.0100e-07 - acc: 1.000 - ETA: 1s - loss: 6.0385e-07 - acc: 1.000 - ETA: 1s - loss: 6.2413e-07 - acc: 1.000 - ETA: 1s - loss: 6.3564e-07 - acc: 1.000 - ETA: 1s - loss: 6.4052e-07 - acc: 1.000 - ETA: 1s - loss: 6.6701e-07 - acc: 1.000 - ETA: 1s - loss: 6.6273e-07 - acc: 1.000 - ETA: 1s - loss: 6.6002e-07 - acc: 1.000 - ETA: 1s - loss: 6.5502e-07 - acc: 1.000 - ETA: 1s - loss: 6.4946e-07 - acc: 1.000 - ETA: 1s - loss: 6.4405e-07 - acc: 1.000 - ETA: 1s - loss: 6.4159e-07 - acc: 1.000 - ETA: 1s - loss: 6.3606e-07 - acc: 1.000 - ETA: 1s - loss: 6.3529e-07 - acc: 1.000 - ETA: 1s - loss: 6.4079e-07 - acc: 1.000 - ETA: 1s - loss: 6.3689e-07 - acc: 1.000 - ETA: 1s - loss: 6.3374e-07 - acc: 1.000 - ETA: 0s - loss: 6.3051e-07 - acc: 1.000 - ETA: 0s - loss: 6.3548e-07 - acc: 1.000 - ETA: 0s - loss: 6.3464e-07 - acc: 1.000 - ETA: 0s - loss: 6.3092e-07 - acc: 1.000 - ETA: 0s - loss: 6.3656e-07 - acc: 1.000 - ETA: 0s - loss: 6.3490e-07 - acc: 1.000 - ETA: 0s - loss: 6.3447e-07 - acc: 1.000 - ETA: 0s - loss: 6.3412e-07 - acc: 1.000 - ETA: 0s - loss: 6.3105e-07 - acc: 1.000 - ETA: 0s - loss: 6.3062e-07 - acc: 1.000 - ETA: 0s - loss: 6.3035e-07 - acc: 1.000 - ETA: 0s - loss: 6.2510e-07 - acc: 1.000 - ETA: 0s - loss: 6.2205e-07 - acc: 1.000 - ETA: 0s - loss: 6.2038e-07 - acc: 1.000 - ETA: 0s - loss: 6.1751e-07 - acc: 1.000 - ETA: 0s - loss: 6.2040e-07 - acc: 1.000 - ETA: 0s - loss: 6.2232e-07 - acc: 1.000 - ETA: 0s - loss: 6.2180e-07 - acc: 1.000 - ETA: 0s - loss: 6.2148e-07 - acc: 1.000 - 5s 198us/sample - loss: 6.2081e-07 - acc: 1.0000 - val_loss: 1.4961 - val_acc: 0.8115\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 3s - loss: 6.0722e-07 - acc: 1.000 - ETA: 3s - loss: 4.0634e-07 - acc: 1.000 - ETA: 3s - loss: 3.9131e-07 - acc: 1.000 - ETA: 3s - loss: 3.8603e-07 - acc: 1.000 - ETA: 3s - loss: 3.7253e-07 - acc: 1.000 - ETA: 3s - loss: 3.7924e-07 - acc: 1.000 - ETA: 3s - loss: 3.7765e-07 - acc: 1.000 - ETA: 3s - loss: 3.8307e-07 - acc: 1.000 - ETA: 3s - loss: 3.8430e-07 - acc: 1.000 - ETA: 3s - loss: 3.8188e-07 - acc: 1.000 - ETA: 3s - loss: 3.8861e-07 - acc: 1.000 - ETA: 2s - loss: 4.0054e-07 - acc: 1.000 - ETA: 2s - loss: 3.9419e-07 - acc: 1.000 - ETA: 2s - loss: 4.0462e-07 - acc: 1.000 - ETA: 2s - loss: 4.3906e-07 - acc: 1.000 - ETA: 2s - loss: 4.3875e-07 - acc: 1.000 - ETA: 2s - loss: 4.3547e-07 - acc: 1.000 - ETA: 2s - loss: 4.3546e-07 - acc: 1.000 - ETA: 2s - loss: 4.4521e-07 - acc: 1.000 - ETA: 2s - loss: 4.3947e-07 - acc: 1.000 - ETA: 2s - loss: 4.3112e-07 - acc: 1.000 - ETA: 2s - loss: 4.3312e-07 - acc: 1.000 - ETA: 2s - loss: 4.3868e-07 - acc: 1.000 - ETA: 2s - loss: 4.3294e-07 - acc: 1.000 - ETA: 2s - loss: 4.4004e-07 - acc: 1.000 - ETA: 2s - loss: 4.3339e-07 - acc: 1.000 - ETA: 2s - loss: 4.3194e-07 - acc: 1.000 - ETA: 2s - loss: 4.4231e-07 - acc: 1.000 - ETA: 2s - loss: 4.4146e-07 - acc: 1.000 - ETA: 2s - loss: 4.4045e-07 - acc: 1.000 - ETA: 2s - loss: 4.3855e-07 - acc: 1.000 - ETA: 1s - loss: 4.3569e-07 - acc: 1.000 - ETA: 1s - loss: 4.3232e-07 - acc: 1.000 - ETA: 1s - loss: 4.3739e-07 - acc: 1.000 - ETA: 1s - loss: 4.3981e-07 - acc: 1.000 - ETA: 1s - loss: 4.4094e-07 - acc: 1.000 - ETA: 1s - loss: 4.4292e-07 - acc: 1.000 - ETA: 1s - loss: 4.3910e-07 - acc: 1.000 - ETA: 1s - loss: 4.4065e-07 - acc: 1.000 - ETA: 1s - loss: 4.4088e-07 - acc: 1.000 - ETA: 1s - loss: 4.4339e-07 - acc: 1.000 - ETA: 1s - loss: 4.4396e-07 - acc: 1.000 - ETA: 1s - loss: 4.4297e-07 - acc: 1.000 - ETA: 1s - loss: 4.4859e-07 - acc: 1.000 - ETA: 1s - loss: 4.4753e-07 - acc: 1.000 - ETA: 1s - loss: 4.4527e-07 - acc: 1.000 - ETA: 1s - loss: 4.4775e-07 - acc: 1.000 - ETA: 1s - loss: 4.5081e-07 - acc: 1.000 - ETA: 1s - loss: 4.6102e-07 - acc: 1.000 - ETA: 1s - loss: 4.6560e-07 - acc: 1.000 - ETA: 0s - loss: 4.6767e-07 - acc: 1.000 - ETA: 0s - loss: 4.6638e-07 - acc: 1.000 - ETA: 0s - loss: 4.6594e-07 - acc: 1.000 - ETA: 0s - loss: 4.6473e-07 - acc: 1.000 - ETA: 0s - loss: 4.6329e-07 - acc: 1.000 - ETA: 0s - loss: 4.6185e-07 - acc: 1.000 - ETA: 0s - loss: 4.6094e-07 - acc: 1.000 - ETA: 0s - loss: 4.5907e-07 - acc: 1.000 - ETA: 0s - loss: 4.5744e-07 - acc: 1.000 - ETA: 0s - loss: 4.5770e-07 - acc: 1.000 - ETA: 0s - loss: 4.6289e-07 - acc: 1.000 - ETA: 0s - loss: 4.6062e-07 - acc: 1.000 - ETA: 0s - loss: 4.6169e-07 - acc: 1.000 - ETA: 0s - loss: 4.6287e-07 - acc: 1.000 - ETA: 0s - loss: 4.6435e-07 - acc: 1.000 - ETA: 0s - loss: 4.6402e-07 - acc: 1.000 - ETA: 0s - loss: 4.6213e-07 - acc: 1.000 - ETA: 0s - loss: 5.1160e-07 - acc: 1.000 - ETA: 0s - loss: 5.1077e-07 - acc: 1.000 - 5s 195us/sample - loss: 5.1308e-07 - acc: 1.0000 - val_loss: 1.4966 - val_acc: 0.8114\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - ETA: 5s - loss: 2.6263e-07 - acc: 1.000 - ETA: 3s - loss: 2.6364e-07 - acc: 1.000 - ETA: 3s - loss: 3.5328e-07 - acc: 1.000 - ETA: 3s - loss: 3.5225e-07 - acc: 1.000 - ETA: 3s - loss: 3.4007e-07 - acc: 1.000 - ETA: 3s - loss: 3.2895e-07 - acc: 1.000 - ETA: 3s - loss: 3.4039e-07 - acc: 1.000 - ETA: 3s - loss: 3.3774e-07 - acc: 1.000 - ETA: 3s - loss: 3.4393e-07 - acc: 1.000 - ETA: 3s - loss: 3.3354e-07 - acc: 1.000 - ETA: 3s - loss: 3.3068e-07 - acc: 1.000 - ETA: 3s - loss: 3.4449e-07 - acc: 1.000 - ETA: 3s - loss: 3.4301e-07 - acc: 1.000 - ETA: 2s - loss: 3.4567e-07 - acc: 1.000 - ETA: 2s - loss: 3.4673e-07 - acc: 1.000 - ETA: 2s - loss: 3.5584e-07 - acc: 1.000 - ETA: 2s - loss: 3.5173e-07 - acc: 1.000 - ETA: 2s - loss: 3.5453e-07 - acc: 1.000 - ETA: 2s - loss: 3.5953e-07 - acc: 1.000 - ETA: 2s - loss: 3.5867e-07 - acc: 1.000 - ETA: 2s - loss: 3.6167e-07 - acc: 1.000 - ETA: 2s - loss: 3.5795e-07 - acc: 1.000 - ETA: 2s - loss: 3.6372e-07 - acc: 1.000 - ETA: 2s - loss: 3.8023e-07 - acc: 1.000 - ETA: 2s - loss: 3.7798e-07 - acc: 1.000 - ETA: 2s - loss: 3.7468e-07 - acc: 1.000 - ETA: 2s - loss: 3.7648e-07 - acc: 1.000 - ETA: 2s - loss: 3.8167e-07 - acc: 1.000 - ETA: 2s - loss: 3.7963e-07 - acc: 1.000 - ETA: 2s - loss: 3.7718e-07 - acc: 1.000 - ETA: 2s - loss: 3.7913e-07 - acc: 1.000 - ETA: 1s - loss: 3.7640e-07 - acc: 1.000 - ETA: 1s - loss: 3.7475e-07 - acc: 1.000 - ETA: 1s - loss: 3.7001e-07 - acc: 1.000 - ETA: 1s - loss: 3.7088e-07 - acc: 1.000 - ETA: 1s - loss: 4.0087e-07 - acc: 1.000 - ETA: 1s - loss: 3.9853e-07 - acc: 1.000 - ETA: 1s - loss: 3.9789e-07 - acc: 1.000 - ETA: 1s - loss: 4.0182e-07 - acc: 1.000 - ETA: 1s - loss: 4.0006e-07 - acc: 1.000 - ETA: 1s - loss: 3.9969e-07 - acc: 1.000 - ETA: 1s - loss: 4.0073e-07 - acc: 1.000 - ETA: 1s - loss: 3.9924e-07 - acc: 1.000 - ETA: 1s - loss: 3.9937e-07 - acc: 1.000 - ETA: 1s - loss: 4.0874e-07 - acc: 1.000 - ETA: 1s - loss: 4.1005e-07 - acc: 1.000 - ETA: 1s - loss: 4.2192e-07 - acc: 1.000 - ETA: 1s - loss: 4.2222e-07 - acc: 1.000 - ETA: 1s - loss: 4.2050e-07 - acc: 1.000 - ETA: 1s - loss: 4.1957e-07 - acc: 1.000 - ETA: 0s - loss: 4.1734e-07 - acc: 1.000 - ETA: 0s - loss: 4.1666e-07 - acc: 1.000 - ETA: 0s - loss: 4.1456e-07 - acc: 1.000 - ETA: 0s - loss: 4.1167e-07 - acc: 1.000 - ETA: 0s - loss: 4.1122e-07 - acc: 1.000 - ETA: 0s - loss: 4.1020e-07 - acc: 1.000 - ETA: 0s - loss: 4.1753e-07 - acc: 1.000 - ETA: 0s - loss: 4.1740e-07 - acc: 1.000 - ETA: 0s - loss: 4.1330e-07 - acc: 1.000 - ETA: 0s - loss: 4.1593e-07 - acc: 1.000 - ETA: 0s - loss: 4.1567e-07 - acc: 1.000 - ETA: 0s - loss: 4.1510e-07 - acc: 1.000 - ETA: 0s - loss: 4.1780e-07 - acc: 1.000 - ETA: 0s - loss: 4.1613e-07 - acc: 1.000 - ETA: 0s - loss: 4.1519e-07 - acc: 1.000 - ETA: 0s - loss: 4.1524e-07 - acc: 1.000 - ETA: 0s - loss: 4.1505e-07 - acc: 1.000 - ETA: 0s - loss: 4.1345e-07 - acc: 1.000 - ETA: 0s - loss: 4.1575e-07 - acc: 1.000 - 5s 191us/sample - loss: 4.1708e-07 - acc: 1.0000 - val_loss: 1.4985 - val_acc: 0.8118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d41f1314e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
